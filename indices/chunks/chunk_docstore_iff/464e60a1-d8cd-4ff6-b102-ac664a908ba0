{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "self.one_sided = one_sided\n\nself.seed = random_seed\n\nself.bootstrap_num_iter = bootstrap_num_iter\n\nself.bootstrap_percent = bootstrap_percent\n\nlogging.info('ModelCompare instance created.')\n\ndef bootstrap_test(self, new_model: Union[ClassifierMixin, RegressorMixin], old_model: Union[ClassifierMixin, RegressorMixin], x_test: Union[np.ndarray, pd.DataFrame], y_test: Union[np.ndarray, pd.Series]) -> Tuple[List[float], List[float]]: \"\"\" Performs a bootstrap test on the input models, generating performance scores for each iteration.\n\nArgs: new_model (Union[ClassifierMixin, RegressorMixin]): The first model to compare. old_model (Union[ClassifierMixin, RegressorMixin]): The second model to compare. x_test (Union[np.ndarray, pd.DataFrame]): The test data features. y_test (Union[np.ndarray, pd.Series]): The test data target values.\n\nReturns: Tuple[List[float], List[float]]: Lists of performance scores for the new_model and old_model, respectively. \"\"\"\n\nlogging.debug('Running bootstrap_test.')\n\nif isinstance(x_test, np.ndarray): # Bootstrap using numpy random choice bootstrap = np.random.choice elif isinstance(x_test, pd.DataFrame): # Bootstrap using pandas sample bootstrap = pd.DataFrame.sample x_test = x_test.reset_index(drop = True)\n\ny_test = y_test.reset_index(drop = True) if isinstance(y_test, pd.Series) else y_test\n\nif isinstance(new_model, ClassifierMixin): evaluation_metrics = {'accuracy': accuracy_score, 'f1': f1_score, 'recall': recall_score, 'roc': roc_auc_score} elif isinstance(new_model, RegressorMixin): evaluation_metrics = {'mae': mean_absolute_error, 'mse': mean_squared_error, 'r2': r2_score} else: raise ValueError('Invalid model type. Must be a classifier or a regressor.')\n\nevaluation_metric = evaluation_metrics[self.evaluation_metric]\n\nnew_model_scores = []\n\nold_model_scores = []\n\nbootstrap_size = int(self.bootstrap_percent\n\nlen(x_test))", "metadata": {"source": "./documents/IFF/model_compare.py"}, "type": "Document"}}