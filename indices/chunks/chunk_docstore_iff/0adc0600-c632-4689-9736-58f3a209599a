{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "return np.array(bootstrapped_means)\n\ndef perform_t_test(self, data1: np.ndarray, data2: np.ndarray, alpha: float = 0.05) -> bool: \"\"\" Perform a two-sample t-test on the given data and determine whether to reject the null hypothesis.\n\nArgs: data1 (np.ndarray): A NumPy array containing data for the first population. data2 (np.ndarray): A NumPy array containing data for the second population. alpha (float): Significance level.\n\nReturns: bool: True if the null hypothesis should be rejected, False otherwise. \"\"\" t_stat, p_val = stats.ttest_ind(data2, data1, alternative = 'greater') return p_val < alpha\n\ndef simulate_power(self, p2: float, size: int, alpha: float = 0.05) -> float: \"\"\" Simulate the power of the statistical test based on the provided parameters.\n\nArgs: p2 (float): Probability of success for population 2. size (int): Size of the original populations. alpha (float): Significance level.\n\nReturns: float: The estimated power of the statistical test. \"\"\" num_rejections = 0 for j in range(self.num_simulations):\n\ndata1, data2 = self.generate_binomial_data(p2, size, j) self.accuracy_scores1 = self.bootstrap_accuracy_scores(data1, j) self.accuracy_scores2 = self.bootstrap_accuracy_scores(data2, j)\n\nif self.perform_t_test(self.accuracy_scores1, self.accuracy_scores2, alpha):\n\nnum_rejections += 1\n\nself.power = num_rejections / self.num_simulations\n\nreturn self.power\n\ndef generate_fourth_attribute(self, fixed_attributes: Dict[str, float], target: str) -> Union[float, int]: \"\"\" Generate the value of the fourth attribute by holding the other three attributes constant.\n\nArgs: fixed_attributes (dict): A dictionary containing the fixed attributes (p2, size, alpha, and power). target (str): The attribute to be generated. One of \"p2\", \"size\", \"alpha\", or \"power\".", "metadata": {"source": "./documents/IFF/power_simulation.py"}, "type": "Document"}}