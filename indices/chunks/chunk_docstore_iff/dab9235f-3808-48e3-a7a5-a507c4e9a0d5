{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "dataset a sufficient way to evaluate the new model? How do we compare the performance of the new and old models in a more generalizable fashion?\n\nTo address those problems, we developed a proprietary Python package called iff-model-compare to compare two ML models in a statistically robust way (Figure 4). The package has two modules: ModelCompare and PowerSimu- lation. In ModelCompare, the test data is first bootstrapped, and each bootstrap is evaluated using the new and old ML models. The two arrays of evaluation scores were then compared using a two-sample independent t test. The user has the option to choose the size of each bootstrap, the number of bootstraps, the evaluation metric, the alpha value for the t test, and the one-sided/two-sided-ness of the t test.\n\nFig. 4. Workflow of the ModelCompare module.\n\nIn PowerSimulation, we evaluate the quality of a t test by finding its power. We first generate synthetic data using the accuracy scores that the user provides, and then, using the same bootstrap approach as in ModelCompare, we repeatedly bootstrap from the synthetic data and conduct the t test \u2013 the percentage of times we reject the null hypothesis (that there is no significant difference between the two models) is the power of the t test. To address the potential issue of limited test data size, we \u201cbacktrack\u201d the process of power simulation to find the minimum test data size required to reach the desired power. This is possible because test data size is correlated with power. Additionally, the visualization method of the PowerSimulation module allows the user more directly visualize the relationship between power, test data size, and effect size (Figure 5).\n\nAltogehter, the iff-model-compare Python package pro- vides a complete workflow that allows the user to first estimate the minimum test data size and then performance model comparison on the test data (Figure 6).\n\nV. CONCLUSION", "metadata": {"source": "./documents/IFF/internship_report.pdf"}, "type": "Document"}}