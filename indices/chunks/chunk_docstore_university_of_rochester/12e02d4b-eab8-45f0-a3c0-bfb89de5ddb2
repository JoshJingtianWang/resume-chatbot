{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "classifier\n\nWHAT HAS NOT BEEN DONE AND WHAT IS THE NOVELTY IN OUR STUDY COMPARED WITH THE ABOVE STUDIES\n\nIn this project, we took inspiration from the Google Landmark Recognition 2020 Competition (https://www.kaggle.com/c/landmark-recognition-2020). We also used concepts such as image retrieval (https://arxiv.org/abs/1711.02512, https://arxiv.org/abs/2001.05027), GeM Pooling\n\n(https://arxiv.org/abs/1902.05509v2) and ArcFaceLoss (https://arxiv.org/abs/1801.07698) \u2013 techniques often used in facial recognition tasks.\n\n3.\n\nMethods\n\nThe model we built is shown is figure 1.\n\nFigure 1. Project's training model\n\nAs can be seen in figure 1, the model consists of two major parts: the first part is the EffNet which extracts the main features of image and the second part uses embedded features generated by the first part, to categorize data utilizing the k-nearest neighborhood algorithm.\n\n1.\n\nNetwork, Loss, and Pooling\n\nWe use the pre-trained EfficientNet Network in our implementation. Also, as the traditional loss functions may not give the potential best result, the Additive Angular Margin Loss or the so-called ArcFace is applied in our implementation. Based on the literature, the ArcFace loss provides appropriate loss functions that enhance discriminative power in deep convolutional neural networks [11] and it has outperformed the competent loss functions and can be easily implemented with trivial computational overhead [12].\n\nIn addition, GeM Pooling [13] which is used in the model, is mentioned to be useful in the most\n\nrelevant discussions, it is a trainable representation of the dimensionality reduction layer between the average pooling and the max pooling.\n\nFigure 2. Equation for GeM Pooling (https://arxiv.org/abs/1902.05509v2). GeM Pooling can be represented in the figure above. In max pooling, pk\u2192\u221e; in average pooling, pk =\n\n1. In GeM Pooling, pk can be manually set or learned since this operation is differentiable and can be part of the back-propagation.", "metadata": {"source": "./documents/University of Rochester/deep learning project report.pdf"}, "type": "Document"}}