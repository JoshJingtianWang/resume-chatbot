{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "1. In GeM Pooling, pk can be manually set or learned since this operation is differentiable and can be part of the back-propagation.\n\nWe used the embeddings extracted from the training data to train the KNN clustering model.\n\nFigure 3. Making predictions on the test images.\n\nNext, we fed the test images into the trained EffNet and extracted the embeddings. Predictions were\n\nmade on the embeddings using the KNN trained previously.\n\n2.\n\nDataset\n\nWe obtained the data from the Happy Dolphin and Whale Image classification competition. We split a training set and a test set from the data. The split ratio is 80% training and 20% test. Also, in developing our dataset, we resized all the images to be square (128x128 resolution) and normalized the values within the image tensors. Furthermore, based on the community discussions, we implemented training and test data loader to give 16 images for each batch. Each image has 3 RBG channels. Thus, each batch dimensions is as follows: 16\u00d73\u00d7128\u00d712816\u00d73\u00d7128\u00d7128\n\n4.\n\nResults\n\nFigure 4. Result of clustering using the baseline model.\n\nAs a sanity check, we inspected the clustering result of the training data from the KNN model (Fig. 4). Although\n\nimages in each cluster appear similar, they seem to be grouped based on the background of the images.\n\nTo eliminate the background influence, we used an object detection tool Detic\n\n(https://github.com/facebookresearch/Detic ) to crop out the background. We also removed flipping in image augmentation since most of the markings on the animals are not symmetrical.\n\nFigure 5. Result of clustering after making several changes. The new result (Fig. 5) showed improved clustering performance. Initial inspection showed more sensical clustering outcome.", "metadata": {"source": "./documents/University of Rochester/deep learning project report.pdf"}, "type": "Document"}}