{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "90 th percentile: 1.798\n\nPage 10\n\nNo preprocessing!!\n\nTraditional image preprocessing like rotation, scaling, noise injection, resizing etc. helps the model to perform better on unseen data.\n\nIn our scenario, this doesn\u2019t apply because \n\nThese are not Images but Energy maps.\n\nThere won\u2019t be any surprises!!\n\nPage 11\n\nModeling Methods and Results\n\nPage 12\n\nUNet Model \n\n(Only Generator)\n\nPYTORCH IMPLEMENTATION\n\nU-Net is a popular CNN architecture used in semantic image processing.\n\nConsists encoder - decoder architecture, and skip connections \n\nSkip connections help to mitigate the problem of information loss during downsampling process in the encoder.\n\nPage 13\n\nPage 14\n\nU-Net Model\n\nInput\n\nOutput\n\n U-Net training\n\nTraining objective: minimize (MSE( Target, Output ))\n\nPage 15\n\nPix2Pix\n\n(Generator and Discriminator)\n\nUses PatchGAN\n\nUNet generator\n\nPYTORCH IMPLEMENTATION\n\nFeedback for Generator\n\nReal or Fake?\n\nPredicted image\n\nGenerator in action\n\nInput\n\nPredicted image\n\nActual \n\nImage\n\nBuilt on Conditional Generative Adversarial Networks, with an image as a condition rather than random noise.\n\nPatchGAN discriminator analyzes patches of images rather than the entire image, optimizing for local image structure. \n\nPage 16\n\nInput\n\nGenerator\n\noutput\n\nInput\n\nDiscriminator \n\noutput\n\nfake_disc_output\n\nInput\n\nDiscriminator \n\ntarget\n\nreal_disc_output\n\nGenerator training objective\n\n minimize (MSE(target,output) + Lambda*BCEL(fake_disc_output, np.ones(30,30)))\n\nDiscriminator training objective\n\nminimize (BCEL(true_disc_output, np.ones(30,30))+\n\nBCEL(fake_disc_output, np.zeros(30,30)))\n\n Pix2Pix training\n\nPage 17\n\nMSE is a more meaningful evaluation metric than MAPE\n\nRESULT: SPATIAL DISTRIBUTION OF ERRORS\n\nMean Squared Error (MSE)\n\nMean Absolute Percent Error (MAPE)\n\nPage 18\n\nL1 models outperform L2 models\n\nRecursively trained each of the models 25 times. Each model iteration was tested on 20 bootstrapped test datasets.  \n\nUNet L1\n\nUNet L2\n\nGenerator L1\n\nGenerator L2", "metadata": {"source": "./documents/University of Rochester/GAN_capstone_project_presentation.pptx"}, "type": "Document"}}