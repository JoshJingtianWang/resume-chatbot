{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "Abstract\n\nManually identifying marine mammals such as whales and dolphins can be a strenuous task for marine\n\necologists. In this study, we aim to build a model that automatically groups all images that contain the same individual dolphins and whales to help bio-marine scientists track the life of these marine mammals easier, leading to a substantially reduced tracking time, as compared to time-intensive, the almost inaccurate manual matching method adopted by institutes. To do this, we used EffNet architecture as the building block of the classification model and kNN as the clustering part to do the grouping task on the data. We were able to group together highly similar photographs of body parts of marine mammals and correctly identify species of half of the test subjects on the first try. However, our model was not able to identify individuals with desirable performance. This project serves as a starting point for using image retrieval/facial recognition techniques in ecological research.\n\n1.\n\nIntroduction\n\nDue to historical competition and direct overlap with humans, the population of marine mammals have been heavily influenced by human activities (ref_j1). To answer a wide range of issues in the study of ecosystem function, community and population dynamics, and behavioral ecology, it is essential for researchers to be able to re-identify an individual animal, and novel computer vision plays an essential role in this process [1]. And because vast amounts of image databases are generated from living creatures like marine mammals, these archive archives require a powerful image retrieval mechanism [2].\n\nIn this project, we developed an advanced image retrieval system to distinguish between", "metadata": {"source": "./documents/University of Rochester/deep learning project report.pdf"}, "type": "Document"}}