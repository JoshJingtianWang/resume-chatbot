{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "2. Expand Root Slice: Start by expanding the given root slice (R) and proceed to examine each\n\nslice.\n\n3. Check Effect Size: For each slice in the expanded set, if its effect size is greater than or equal to the threshold (T), it's considered a candidate and added to the priority queue (C). Otherwise, it's considered non-problematic and appended to list N.\n\n4. Significance Testing: For each slice in the priority queue, the algorithm checks if the slice is significant (with respect to the alpha wealth W). If significant and the maximum number of slices is reached (k), the algorithm returns the problematic slices.\n\n5. Update Alpha Wealth: The algorithm updates the alpha wealth (W) accordingly, whether the\n\nslice is found significant or not.\n\n6. Expand Non-Problematic Slices: Increase the number of degrees and expand the non-\n\nproblematic slices.\n\n7. Loop until Termination: The loop continues, expanding slices and examining them, until no\n\nmore slices are found to expand, at which point it returns the problematic slices.\n\nTable 1. SliceFinder detailed algorithm.\n\nAs seen in Figure 2, as the number of degrees increases, SliceFinder leads to a faster run time than the naive searching algorithm.\n\nFigure 2. Runtime analysis of \u201cbrute-force\u201d crossing algorithm (blue) vs SliceFinder\u2019s algorithm (orange). Data was the event launch flow table\n\n(client_experience_launch_flow_streaming_complexity). Target was the last milestone of the launch flow.\n\nFalse Discovery Rate (FDR) control in SliceFinder:\n\nFDR control in SliceFinder is done via alpha-investing: Given an alpha-wealth (overall Type I error rate) \u03b1, alpha-investing spends this over multiple comparisons, while increasing the budget \u03b1 towards the subsequent tests with each rejected hypothesis.", "metadata": {"source": "./documents/Roblox/Josh Wang Internship at Roblox Report.pdf"}, "type": "Document"}}